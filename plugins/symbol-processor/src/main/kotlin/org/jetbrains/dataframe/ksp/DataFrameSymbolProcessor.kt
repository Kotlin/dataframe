package org.jetbrains.dataframe.ksp

import com.google.devtools.ksp.KspExperimental
import com.google.devtools.ksp.getAnnotationsByType
import com.google.devtools.ksp.processing.CodeGenerator
import com.google.devtools.ksp.processing.KSPLogger
import com.google.devtools.ksp.processing.Resolver
import com.google.devtools.ksp.processing.SymbolProcessor
import com.google.devtools.ksp.symbol.KSAnnotated
import com.google.devtools.ksp.symbol.KSClassDeclaration
import com.google.devtools.ksp.validate
import kotlinx.serialization.json.JsonPrimitive
import org.jetbrains.kotlinx.dataframe.annotations.DataSchemaSource
import org.jetbrains.kotlinx.dataframe.api.schema
import org.jetbrains.kotlinx.dataframe.io.SchemaReader
import java.io.File
import java.util.ServiceLoader

class DataFrameSymbolProcessor(
    private val codeGenerator: CodeGenerator,
    private val logger: KSPLogger,
    private val configuration: DataFrameConfiguration,
) : SymbolProcessor {

    @OptIn(KspExperimental::class)
    override fun process(resolver: Resolver): List<KSAnnotated> {
        if (!configuration.experimentalImportSchema) {
            val extensionsGenerator = ExtensionsGenerator(resolver, codeGenerator, logger)
            val (validDataSchemas, invalidDataSchemas) = extensionsGenerator.resolveDataSchemaDeclarations()
            validDataSchemas.forEach {
                val file = it.origin.containingFile ?: return@forEach
                extensionsGenerator.generateExtensions(file, it.origin, it.properties)
            }

            val dataSchemaGenerator = DataSchemaGenerator(resolver, configuration.resolutionDir, logger, codeGenerator)
            val importStatements = dataSchemaGenerator.resolveImportStatements()
            importStatements.forEach { importStatement ->
                dataSchemaGenerator.generateDataSchema(importStatement)
            }
            // by returning invalidDataSchemas we defer the processing of incomplete DataSchema declarations
            // for example when DataSchema declaration references another one generated by @file:ImportDataSchema
            return invalidDataSchemas
        }

        val serviceLoader = ServiceLoader.load(SchemaReader::class.java, SchemaReader::class.java.classLoader)
        val providers = serviceLoader.toList()

        if (configuration.debug) {
            logger.warn("Service path: " + System.getProperty("java.class.path"))
            logger.warn("Found providers: " + providers.joinToString())
            logger.warn(
                "Service URLs: " +
                    SchemaReader::class.java.classLoader?.getResources(
                        "META-INF/services/${SchemaReader::class.java.name}",
                    )
                        ?.toList()?.joinToString(),
            )
        }

        if (configuration.importedSchemasOutput == null) {
            logger.warn(
                """
                Provide KSP argument:
                ksp {
                  arg("$DATAFRAME_IMPORTED_SCHEMAS_OUTPUT", layout.projectDirectory.dir("src/schemas"))
                }
                """.trimIndent(),
            )
            return emptyList()
        }

        val (validDeclarations, invalidDeclarations) = resolver
            .getSymbolsWithAnnotation(DataSchemaSource::class.qualifiedName!!)
            .filterIsInstance<KSClassDeclaration>()
            .flatMap { classDeclaration ->
                classDeclaration.getAnnotationsByType(DataSchemaSource::class).map { classDeclaration to it }
            }
            .partition { it.first.validate() }

        val outputDirectory = File(configuration.importedSchemasOutput)
        validDeclarations
            .forEach { (classDeclaration, annotation) ->
                val reader = providers.firstOrNull { it.accepts(annotation.source, annotation.qualifier) }
                if (reader != null) {
                    val metadata = mapOf(
                        "format" to JsonPrimitive(reader::class.qualifiedName!!),
                        "data" to JsonPrimitive(annotation.source),
                    )
                    val df = reader.default(annotation.source)
                    if (!outputDirectory.exists()) {
                        outputDirectory.mkdirs()
                    }
                    File(
                        outputDirectory,
                        "${classDeclaration.simpleName.asString()}.json",
                    ).writeText(df.schema().toJsonString(metadata = metadata))
                } else {
                    val availableReaders = providers.joinToString { it::class.qualifiedName!! }
                    val message =
                        "No reader found for ${classDeclaration.simpleName.asString()}. Available readers: $availableReaders"
                    logger.warn(message)
                }
            }

        return invalidDeclarations.map { it.first }
    }
}
